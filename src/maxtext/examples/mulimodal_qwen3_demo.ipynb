{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a711ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash tools/setup/setup.sh\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef6274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/home/abdo1819/my-dataset/hf_cache'\n",
    "os.environ['HF_HUB_CACHE'] = '/home/abdo1819/my-dataset/hf_cache/hub'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/home/abdo1819/my-dataset/hf_cache/datasets'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/abdo1819/my-dataset/hf_cache/transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 15:59:18.857415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770393558.881710   90136 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770393558.889559   90136 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770393558.912983   90136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770393558.913005   90136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770393558.913007   90136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770393558.913009   90136 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/home/abdo1819/venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2026-02-06 15:59:23.285413: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import MaxText\n",
    "\n",
    "MAXTEXT_PKG_DIR = os.path.dirname(MaxText.__file__)\n",
    "MAXTEXT_REPO_ROOT = os.path.dirname(os.path.dirname(MAXTEXT_PKG_DIR))\n",
    "MAXTEXT_ASSETS_ROOT = os.path.join(MAXTEXT_REPO_ROOT, \"src\", \"maxtext\", \"assets\")\n",
    "MODEL_NAME = \"qwen3-omni-30b-a3b\"\n",
    "# Use either a GCS path or a local path for the model checkpoint\n",
    "MODEL_CHECKPOINT_PATH = f\"gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking\"\n",
    "# Replace with your actual Hugging Face token\n",
    "HF_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34551ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdo1819/maxtext\n"
     ]
    }
   ],
   "source": [
    "%cd /home/abdo1819/maxtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd6af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdo1819/maxtext\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e538d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdo1819/venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2026-02-06 16:00:14.563465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770393614.587158   91744 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770393614.594906   91744 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770393614.616326   91744 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770393614.616364   91744 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770393614.616376   91744 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770393614.616381   91744 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-02-06 16:00:17.919565: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:Type handler registry overriding type \"<class '__main__.LazyTensor'>\" collision on np.ndarray\n",
      "INFO:absl:Skipping jax distributed system due to skip_jax_distributed_system=True flag.\n",
      "INFO:MaxText.pyconfig:Config param act_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param activation_dropout_for_audio: 0.0\n",
      "INFO:MaxText.pyconfig:Config param activation_function_for_audio: gelu\n",
      "INFO:MaxText.pyconfig:Config param activations_in_float32: False\n",
      "INFO:MaxText.pyconfig:Config param adam_b1: 0.9\n",
      "INFO:MaxText.pyconfig:Config param adam_b2: 0.95\n",
      "INFO:MaxText.pyconfig:Config param adam_eps: 1e-08\n",
      "INFO:MaxText.pyconfig:Config param adam_eps_root: 0.0\n",
      "INFO:MaxText.pyconfig:Config param adam_weight_decay: 0.1\n",
      "INFO:MaxText.pyconfig:Config param add_bos: True\n",
      "INFO:MaxText.pyconfig:Config param add_eos: True\n",
      "INFO:MaxText.pyconfig:Config param allow_split_physical_axes: False\n",
      "INFO:MaxText.pyconfig:Config param ar_cache_axis_order: 1,2,0,3\n",
      "INFO:MaxText.pyconfig:Config param async_checkpointing: True\n",
      "INFO:MaxText.pyconfig:Config param attention: autoselected\n",
      "INFO:MaxText.pyconfig:Config param attention_bias: False\n",
      "INFO:MaxText.pyconfig:Config param attention_dropout_for_audio: 0.0\n",
      "INFO:MaxText.pyconfig:Config param attention_sink: False\n",
      "INFO:MaxText.pyconfig:Config param attention_type: global\n",
      "INFO:MaxText.pyconfig:Config param attn_logits_soft_cap: None\n",
      "INFO:MaxText.pyconfig:Config param audio_path: \n",
      "INFO:MaxText.pyconfig:Config param autoregressive_decode_assert: \n",
      "INFO:MaxText.pyconfig:Config param base_config: None\n",
      "INFO:MaxText.pyconfig:Config param base_emb_dim: 2048\n",
      "INFO:MaxText.pyconfig:Config param base_mlp_dim: 768\n",
      "INFO:MaxText.pyconfig:Config param base_moe_mlp_dim: 768\n",
      "INFO:MaxText.pyconfig:Config param base_num_decoder_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param base_num_kv_heads: 4\n",
      "INFO:MaxText.pyconfig:Config param base_num_query_heads: 32\n",
      "INFO:MaxText.pyconfig:Config param base_output_directory: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking\n",
      "INFO:MaxText.pyconfig:Config param batch_size: 1\n",
      "INFO:MaxText.pyconfig:Config param beta_fast: 32\n",
      "INFO:MaxText.pyconfig:Config param beta_slow: 1\n",
      "INFO:MaxText.pyconfig:Config param bwd_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param capacity_factor: -1.0\n",
      "INFO:MaxText.pyconfig:Config param cast_logits_to_fp32: True\n",
      "INFO:MaxText.pyconfig:Config param chat_template_path: \n",
      "INFO:MaxText.pyconfig:Config param checkpoint_conversion_fn: None\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_dir: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking/qwen3-omni-30b-a3b_2026-02-06-16-00/checkpoints/\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_is_quantized: False\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_period: 10000\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_concurrent_gb: 96\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_target_data_file_size_bytes: 2147483648\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_use_ocdbt: True\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_use_zarr3: True\n",
      "INFO:MaxText.pyconfig:Config param chips_per_vm: 4\n",
      "INFO:MaxText.pyconfig:Config param chunk_attn_window_size: 0\n",
      "INFO:MaxText.pyconfig:Config param collect_stack_trace: False\n",
      "INFO:MaxText.pyconfig:Config param colocated_python_data_input: False\n",
      "INFO:MaxText.pyconfig:Config param compile_topology: \n",
      "INFO:MaxText.pyconfig:Config param compile_topology_num_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param compiled_trainstep_file: \n",
      "INFO:MaxText.pyconfig:Config param compute_axis_order: 0,1,2,3\n",
      "INFO:MaxText.pyconfig:Config param constant_bound_config: []\n",
      "INFO:MaxText.pyconfig:Config param context: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_load_balance: True\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_size: 1\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_strategy: all_gather\n",
      "INFO:MaxText.pyconfig:Config param conv_chunksize_for_audio: 500\n",
      "INFO:MaxText.pyconfig:Config param conv_stride_for_vit: 14\n",
      "INFO:MaxText.pyconfig:Config param cost_estimate_flops_bwd: -1\n",
      "INFO:MaxText.pyconfig:Config param cost_estimate_flops_fwd: -1\n",
      "INFO:MaxText.pyconfig:Config param custom_mesh: \n",
      "INFO:MaxText.pyconfig:Config param d_model_for_audio: 1280\n",
      "INFO:MaxText.pyconfig:Config param data_sharding: ()\n",
      "INFO:MaxText.pyconfig:Config param data_shuffle_seed: 0\n",
      "INFO:MaxText.pyconfig:Config param dataset_name: c4/en:3.0.1\n",
      "INFO:MaxText.pyconfig:Config param dataset_path: \n",
      "INFO:MaxText.pyconfig:Config param dataset_type: DatasetType.TFDS\n",
      "INFO:MaxText.pyconfig:Config param dcn_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_context_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_context_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_data_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param dcn_expert_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_fsdp_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_fsdp_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_parallelism: [-1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:MaxText.pyconfig:Config param dcn_pipeline_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param debug: {'rl': False}\n",
      "INFO:MaxText.pyconfig:Config param debug_sharding: False\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_nucleus_p: -1.0\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_strategy: SamplingStrategy.GREEDY\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_temperature: 1.0\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_top_k: 0\n",
      "INFO:MaxText.pyconfig:Config param decoder_block: DecoderBlockType.QWEN3_MOE\n",
      "INFO:MaxText.pyconfig:Config param decoder_layer_input: RematLocation.DEVICE\n",
      "INFO:MaxText.pyconfig:Config param deepstack_visual_indexes_for_vit: [8, 16, 24]\n",
      "INFO:MaxText.pyconfig:Config param distill_alpha: 0.5\n",
      "INFO:MaxText.pyconfig:Config param distill_temperature: 1.0\n",
      "INFO:MaxText.pyconfig:Config param downsample_hidden_size_for_audio: 480\n",
      "INFO:MaxText.pyconfig:Config param dpo_beta: 0.1\n",
      "INFO:MaxText.pyconfig:Config param dpo_label_smoothing: 0.0\n",
      "INFO:MaxText.pyconfig:Config param dq_reduction_steps: 0\n",
      "INFO:MaxText.pyconfig:Config param dropout_rate: 0.0\n",
      "INFO:MaxText.pyconfig:Config param dtype: bfloat16\n",
      "INFO:MaxText.pyconfig:Config param dtype_mm: float32\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo: False\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_delete_local_after: True\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_gcs_dir: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking/qwen3-omni-30b-a3b_2026-02-06-16-00/xla_dump\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_local_dir: /tmp/xla_dump/\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_local_module_name: jit_train_step\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_module_name: jit_train_step\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_upload_all: False\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_xla_flags: \n",
      "INFO:MaxText.pyconfig:Config param dump_jaxpr: False\n",
      "INFO:MaxText.pyconfig:Config param dump_jaxpr_delete_local_after: True\n",
      "INFO:MaxText.pyconfig:Config param dump_jaxpr_gcs_dir: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking/qwen3-omni-30b-a3b_2026-02-06-16-00/jaxpr_dump\n",
      "INFO:MaxText.pyconfig:Config param dump_jaxpr_local_dir: /tmp/jaxpr_dump/\n",
      "INFO:MaxText.pyconfig:Config param dump_step: -1\n",
      "INFO:MaxText.pyconfig:Config param emb_dim: 2048\n",
      "INFO:MaxText.pyconfig:Config param enable_checkpoint_cloud_logger: False\n",
      "INFO:MaxText.pyconfig:Config param enable_checkpointing: True\n",
      "INFO:MaxText.pyconfig:Config param enable_continuous_checkpointing: False\n",
      "INFO:MaxText.pyconfig:Config param enable_data_shuffling: True\n",
      "INFO:MaxText.pyconfig:Config param enable_dp_attention: False\n",
      "INFO:MaxText.pyconfig:Config param enable_dropout: False\n",
      "INFO:MaxText.pyconfig:Config param enable_emergency_checkpoint: False\n",
      "INFO:MaxText.pyconfig:Config param enable_gcp_goodput_metrics: True\n",
      "INFO:MaxText.pyconfig:Config param enable_gcp_step_deviation_metrics: True\n",
      "INFO:MaxText.pyconfig:Config param enable_goodput_recording: False\n",
      "INFO:MaxText.pyconfig:Config param enable_jax_profiler: False\n",
      "INFO:MaxText.pyconfig:Config param enable_llm_inference_pool: False\n",
      "INFO:MaxText.pyconfig:Config param enable_model_warmup: False\n",
      "INFO:MaxText.pyconfig:Config param enable_multi_tier_checkpointing: False\n",
      "INFO:MaxText.pyconfig:Config param enable_nnx: False\n",
      "INFO:MaxText.pyconfig:Config param enable_orbax_v1: False\n",
      "INFO:MaxText.pyconfig:Config param enable_padding_causal_mask: True\n",
      "INFO:MaxText.pyconfig:Config param enable_pathways_goodput: False\n",
      "INFO:MaxText.pyconfig:Config param enable_prefix_caching: False\n",
      "INFO:MaxText.pyconfig:Config param enable_rampup_batch_size: False\n",
      "INFO:MaxText.pyconfig:Config param enable_single_controller: False\n",
      "INFO:MaxText.pyconfig:Config param enable_single_replica_ckpt_restoring: False\n",
      "INFO:MaxText.pyconfig:Config param enable_tensorboard: True\n",
      "INFO:MaxText.pyconfig:Config param enable_tunix_perf_metrics: False\n",
      "INFO:MaxText.pyconfig:Config param encoder_attention_heads_for_audio: 20\n",
      "INFO:MaxText.pyconfig:Config param encoder_ffn_dim_for_audio: 5120\n",
      "INFO:MaxText.pyconfig:Config param encoder_layers_for_audio: 32\n",
      "INFO:MaxText.pyconfig:Config param eval_corr_lst: False\n",
      "INFO:MaxText.pyconfig:Config param eval_data_columns: ['text']\n",
      "INFO:MaxText.pyconfig:Config param eval_dataset_name: c4/en:3.0.1\n",
      "INFO:MaxText.pyconfig:Config param eval_image_column: image\n",
      "INFO:MaxText.pyconfig:Config param eval_interval: -1\n",
      "INFO:MaxText.pyconfig:Config param eval_make_lst: False\n",
      "INFO:MaxText.pyconfig:Config param eval_per_device_batch_size: 12\n",
      "INFO:MaxText.pyconfig:Config param eval_sampling_strategy: greedy\n",
      "INFO:MaxText.pyconfig:Config param eval_split: validation\n",
      "INFO:MaxText.pyconfig:Config param eval_steps: -1\n",
      "INFO:MaxText.pyconfig:Config param expansion_factor_real_data: -1.0\n",
      "INFO:MaxText.pyconfig:Config param expert_shard_attention_option: fsdp\n",
      "INFO:MaxText.pyconfig:Config param final_logits_soft_cap: None\n",
      "INFO:MaxText.pyconfig:Config param first_num_dense_layers: 0\n",
      "INFO:MaxText.pyconfig:Config param float32_logits: False\n",
      "INFO:MaxText.pyconfig:Config param float32_qk_product: False\n",
      "INFO:MaxText.pyconfig:Config param float32_weight_sum: True\n",
      "INFO:MaxText.pyconfig:Config param force_q_layout: False\n",
      "INFO:MaxText.pyconfig:Config param force_unroll: False\n",
      "INFO:MaxText.pyconfig:Config param freeze_audio_encoder_params: True\n",
      "INFO:MaxText.pyconfig:Config param freeze_vision_encoder_params: True\n",
      "INFO:MaxText.pyconfig:Config param fused_mlp: False\n",
      "INFO:MaxText.pyconfig:Config param fused_qkv: False\n",
      "INFO:MaxText.pyconfig:Config param gcs_metrics: False\n",
      "INFO:MaxText.pyconfig:Config param gdn_chunk_size: 64\n",
      "INFO:MaxText.pyconfig:Config param gdn_conv_kernel_dim: 4\n",
      "INFO:MaxText.pyconfig:Config param gdn_key_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param gdn_num_key_heads: 16\n",
      "INFO:MaxText.pyconfig:Config param gdn_num_value_heads: 32\n",
      "INFO:MaxText.pyconfig:Config param gdn_value_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param generate_padding_batch_eval: False\n",
      "INFO:MaxText.pyconfig:Config param generate_padding_batch_train: False\n",
      "INFO:MaxText.pyconfig:Config param generate_slice: v5e-16\n",
      "INFO:MaxText.pyconfig:Config param generation_configs: {}\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_eval_on: 192\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load: 192\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_eval: 192\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_increment: None\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_start: None\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_train_on: 192\n",
      "INFO:MaxText.pyconfig:Config param global_parameter_scale: 1\n",
      "INFO:MaxText.pyconfig:Config param global_rampup_samples: 500\n",
      "INFO:MaxText.pyconfig:Config param goodput_upload_interval_seconds: 30\n",
      "INFO:MaxText.pyconfig:Config param grad_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param gradient_accumulation_steps: 1\n",
      "INFO:MaxText.pyconfig:Config param gradient_clipping_threshold: 1.0\n",
      "INFO:MaxText.pyconfig:Config param grain_data_source_max_workers: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_eval_files: \n",
      "INFO:MaxText.pyconfig:Config param grain_file_type: arrayrecord\n",
      "INFO:MaxText.pyconfig:Config param grain_num_threads: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_num_threads_eval: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_packing_type: first_fit\n",
      "INFO:MaxText.pyconfig:Config param grain_per_worker_buffer_size: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_per_worker_buffer_size_eval: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_prefetch_buffer_size: 500\n",
      "INFO:MaxText.pyconfig:Config param grain_prefetch_buffer_size_eval: 500\n",
      "INFO:MaxText.pyconfig:Config param grain_ram_budget_mb: 1024\n",
      "INFO:MaxText.pyconfig:Config param grain_train_files: \n",
      "INFO:MaxText.pyconfig:Config param grain_train_mixture_config_path: \n",
      "INFO:MaxText.pyconfig:Config param grain_worker_count: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_worker_count_eval: 1\n",
      "INFO:MaxText.pyconfig:Config param hardware: tpu\n",
      "INFO:MaxText.pyconfig:Config param hbm_utilization_vllm: 0.72\n",
      "INFO:MaxText.pyconfig:Config param head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param heartbeat_reporting_interval_in_seconds: 5\n",
      "INFO:MaxText.pyconfig:Config param hf_data_dir: \n",
      "INFO:MaxText.pyconfig:Config param hf_eval_files: None\n",
      "INFO:MaxText.pyconfig:Config param hf_eval_split: \n",
      "INFO:MaxText.pyconfig:Config param hf_name: \n",
      "INFO:MaxText.pyconfig:Config param hf_path: \n",
      "INFO:MaxText.pyconfig:Config param hf_train_files: None\n",
      "INFO:MaxText.pyconfig:Config param hidden_size_for_vit: 1152\n",
      "INFO:MaxText.pyconfig:Config param hide_profiler_step_metric: False\n",
      "INFO:MaxText.pyconfig:Config param ici_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_context_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_context_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_data_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_expert_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_fsdp_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param ici_fsdp_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_parallelism: [1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:MaxText.pyconfig:Config param ici_pipeline_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param image_path: \n",
      "INFO:MaxText.pyconfig:Config param image_placeholder: <|image|>\n",
      "INFO:MaxText.pyconfig:Config param image_size_for_vit: 768\n",
      "INFO:MaxText.pyconfig:Config param index_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param index_n_heads: 64\n",
      "INFO:MaxText.pyconfig:Config param index_topk: 2048\n",
      "INFO:MaxText.pyconfig:Config param inference_benchmark_test: False\n",
      "INFO:MaxText.pyconfig:Config param inference_metadata_file: \n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_log_file_path: \n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_loop_iters: 10\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_num_samples: [1, 2, 3, 4, 5]\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_prefill_lengths: 64,128,256,512,1024\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_stages: prefill,generate\n",
      "INFO:MaxText.pyconfig:Config param inference_server: MaxtextInterleavedServer\n",
      "INFO:MaxText.pyconfig:Config param inhomogeneous_layer_cycle_interval: 1\n",
      "INFO:MaxText.pyconfig:Config param init_weights_seed: 0\n",
      "INFO:MaxText.pyconfig:Config param input_data_sharding_logical_axes: ['activation_embed_and_logits_batch', 'activation_norm_length']\n",
      "INFO:MaxText.pyconfig:Config param interleave_moe_layer_step: 1\n",
      "INFO:MaxText.pyconfig:Config param intermediate_size_for_vit: 4304\n",
      "INFO:MaxText.pyconfig:Config param jax_cache_dir: /home/abdo1819/jax_cache\n",
      "INFO:MaxText.pyconfig:Config param jax_debug_log_modules: \n",
      "INFO:MaxText.pyconfig:Config param jax_distributed_initialization_timeout: 300\n",
      "INFO:MaxText.pyconfig:Config param jax_profiler_port: 9999\n",
      "INFO:MaxText.pyconfig:Config param key_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param kv_cache_buffer: 256\n",
      "INFO:MaxText.pyconfig:Config param kv_lora_rank: 512\n",
      "INFO:MaxText.pyconfig:Config param kv_quant_axis: KvQuantAxis.HEADS_AND_DKV\n",
      "INFO:MaxText.pyconfig:Config param kv_quant_dtype: int8\n",
      "INFO:MaxText.pyconfig:Config param learning_rate: 3e-05\n",
      "INFO:MaxText.pyconfig:Config param learning_rate_final_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param learning_rate_schedule_steps: 150001\n",
      "INFO:MaxText.pyconfig:Config param load_balance_loss_weight: 0.0\n",
      "INFO:MaxText.pyconfig:Config param load_from_prefill_dir: False\n",
      "INFO:MaxText.pyconfig:Config param load_full_state_path: \n",
      "INFO:MaxText.pyconfig:Config param load_parameters_path: \n",
      "INFO:MaxText.pyconfig:Config param local_checkpoint_directory: \n",
      "INFO:MaxText.pyconfig:Config param local_checkpoint_period: 0\n",
      "INFO:MaxText.pyconfig:Config param local_rope_max_timescale: -1\n",
      "INFO:MaxText.pyconfig:Config param log_config: True\n",
      "INFO:MaxText.pyconfig:Config param log_period: 100\n",
      "INFO:MaxText.pyconfig:Config param logical_axis_rules: ()\n",
      "INFO:MaxText.pyconfig:Config param logits_dot_in_fp32: False\n",
      "INFO:MaxText.pyconfig:Config param logits_via_embedding: False\n",
      "INFO:MaxText.pyconfig:Config param lora_input_adapters_path: \n",
      "INFO:MaxText.pyconfig:Config param lr_schedule_type: LearningRateScheduleType.COSINE\n",
      "INFO:MaxText.pyconfig:Config param managed_mldiagnostics: False\n",
      "INFO:MaxText.pyconfig:Config param managed_mldiagnostics_dir: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking/qwen3-omni-30b-a3b_2026-02-06-16-00/managed-mldiagnostics\n",
      "INFO:MaxText.pyconfig:Config param managed_mldiagnostics_run_group: \n",
      "INFO:MaxText.pyconfig:Config param matmul_precision: MatmulPrecision.DEFAULT\n",
      "INFO:MaxText.pyconfig:Config param max_checkify: False\n",
      "INFO:MaxText.pyconfig:Config param max_corpus_chars: 10000000\n",
      "INFO:MaxText.pyconfig:Config param max_num_batched_tokens: None\n",
      "INFO:MaxText.pyconfig:Config param max_num_checkpoints_to_keep: None\n",
      "INFO:MaxText.pyconfig:Config param max_num_images_per_example: -1\n",
      "INFO:MaxText.pyconfig:Config param max_num_seqs: None\n",
      "INFO:MaxText.pyconfig:Config param max_position_embeddings: 65536\n",
      "INFO:MaxText.pyconfig:Config param max_prefill_predict_length: 64\n",
      "INFO:MaxText.pyconfig:Config param max_sample_len_for_audio: 10000\n",
      "INFO:MaxText.pyconfig:Config param max_segments_per_seq: -1\n",
      "INFO:MaxText.pyconfig:Config param max_source_positions_for_audio: 1500\n",
      "INFO:MaxText.pyconfig:Config param max_target_length: 2048\n",
      "INFO:MaxText.pyconfig:Config param max_timescale_for_audio: 10000.0\n",
      "INFO:MaxText.pyconfig:Config param megablox: True\n",
      "INFO:MaxText.pyconfig:Config param mesh_axes: ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive']\n",
      "INFO:MaxText.pyconfig:Config param metrics_dir: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking/qwen3-omni-30b-a3b_2026-02-06-16-00/metrics/\n",
      "INFO:MaxText.pyconfig:Config param metrics_file: None\n",
      "INFO:MaxText.pyconfig:Config param mhc_expansion_rate: 0\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size: -1\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size_to_eval_on: 192\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size_to_train_on: 192\n",
      "INFO:MaxText.pyconfig:Config param mla_kv: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mla_naive_kvcache: True\n",
      "INFO:MaxText.pyconfig:Config param mla_q: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlp_activations: ['silu', 'linear']\n",
      "INFO:MaxText.pyconfig:Config param mlp_activations_limit: -1.0\n",
      "INFO:MaxText.pyconfig:Config param mlp_bias: False\n",
      "INFO:MaxText.pyconfig:Config param mlp_dim: 768\n",
      "INFO:MaxText.pyconfig:Config param mlpwi: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwi_0: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwi_1: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwo: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param moba: False\n",
      "INFO:MaxText.pyconfig:Config param moba_chunk_size: 1024\n",
      "INFO:MaxText.pyconfig:Config param moba_topk: 8\n",
      "INFO:MaxText.pyconfig:Config param model_call_mode: \n",
      "INFO:MaxText.pyconfig:Config param model_name: qwen3-omni-30b-a3b\n",
      "INFO:MaxText.pyconfig:Config param moe_fsdp_use_two_stage_all_gather: False\n",
      "INFO:MaxText.pyconfig:Config param moe_mlp_dim: 768\n",
      "INFO:MaxText.pyconfig:Config param monitor_goodput: False\n",
      "INFO:MaxText.pyconfig:Config param monitor_step_time_deviation: True\n",
      "INFO:MaxText.pyconfig:Config param mrope_section: [24, 20, 20]\n",
      "INFO:MaxText.pyconfig:Config param mscale: 1.0\n",
      "INFO:MaxText.pyconfig:Config param mtc_data_parallelism: 0\n",
      "INFO:MaxText.pyconfig:Config param mtp_eval_target_module: 0\n",
      "INFO:MaxText.pyconfig:Config param mtp_loss_scaling_factor: 0.1\n",
      "INFO:MaxText.pyconfig:Config param mtp_num_layers: 0\n",
      "INFO:MaxText.pyconfig:Config param mu_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param multi_sampling: False\n",
      "INFO:MaxText.pyconfig:Config param multi_tier_checkpointing_backup_interval_minutes: 0\n",
      "INFO:MaxText.pyconfig:Config param muon_beta: 0.95\n",
      "INFO:MaxText.pyconfig:Config param muon_consistent_rms: None\n",
      "INFO:MaxText.pyconfig:Config param muon_weight_decay: 0\n",
      "INFO:MaxText.pyconfig:Config param n_routing_groups: -1\n",
      "INFO:MaxText.pyconfig:Config param n_window_for_audio: 50\n",
      "INFO:MaxText.pyconfig:Config param n_window_infer_for_audio: 400\n",
      "INFO:MaxText.pyconfig:Config param nope_layer_interval: -1\n",
      "INFO:MaxText.pyconfig:Config param norm_topk_prob: True\n",
      "INFO:MaxText.pyconfig:Config param normalization_layer_epsilon: 1e-06\n",
      "INFO:MaxText.pyconfig:Config param normalize_embedding_logits: True\n",
      "INFO:MaxText.pyconfig:Config param num_attention_heads_for_vit: 16\n",
      "INFO:MaxText.pyconfig:Config param num_batches: 4\n",
      "INFO:MaxText.pyconfig:Config param num_channels_for_vit: 3\n",
      "INFO:MaxText.pyconfig:Config param num_conv_layers_for_audio: 3\n",
      "INFO:MaxText.pyconfig:Config param num_decoder_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param num_epoch: 1\n",
      "INFO:MaxText.pyconfig:Config param num_eval_passes: 1\n",
      "INFO:MaxText.pyconfig:Config param num_experts: 128\n",
      "INFO:MaxText.pyconfig:Config param num_experts_per_tok: 8\n",
      "INFO:MaxText.pyconfig:Config param num_hidden_layers_for_vit: 27\n",
      "INFO:MaxText.pyconfig:Config param num_kv_heads: 4\n",
      "INFO:MaxText.pyconfig:Config param num_layers_per_pipeline_stage: 1\n",
      "INFO:MaxText.pyconfig:Config param num_mel_bins_for_audio: 128\n",
      "INFO:MaxText.pyconfig:Config param num_pipeline_microbatches: -1\n",
      "INFO:MaxText.pyconfig:Config param num_pipeline_repeats: -1\n",
      "INFO:MaxText.pyconfig:Config param num_position_embeddings_for_vit: 2304\n",
      "INFO:MaxText.pyconfig:Config param num_query_heads: 32\n",
      "INFO:MaxText.pyconfig:Config param num_samplers_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param num_slices: 1\n",
      "INFO:MaxText.pyconfig:Config param num_target_devices: 16\n",
      "INFO:MaxText.pyconfig:Config param num_test_batches: 5\n",
      "INFO:MaxText.pyconfig:Config param num_trainer_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param num_vocab_tiling: 1\n",
      "INFO:MaxText.pyconfig:Config param opt_type: OptimizerType.ADAMW\n",
      "INFO:MaxText.pyconfig:Config param optimize_mesh_for_tpu_v6e: False\n",
      "INFO:MaxText.pyconfig:Config param optimizer_memory_host_offload: False\n",
      "INFO:MaxText.pyconfig:Config param original_max_position_embeddings: 4096\n",
      "INFO:MaxText.pyconfig:Config param out_hidden_size_for_vit: 2048\n",
      "INFO:MaxText.pyconfig:Config param out_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param output_dim_for_audio: 2048\n",
      "INFO:MaxText.pyconfig:Config param override_logical_axis_rules: False\n",
      "INFO:MaxText.pyconfig:Config param override_model_config: False\n",
      "INFO:MaxText.pyconfig:Config param packing: True\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_head_dim_alignment: 128\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_max_pages_per_group: -1\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_num_pages: 64\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_pages_per_compute_block: 4\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_tokens_per_page: 32\n",
      "INFO:MaxText.pyconfig:Config param param_scan_axis: 1\n",
      "INFO:MaxText.pyconfig:Config param parameter_memory_host_offload: False\n",
      "INFO:MaxText.pyconfig:Config param partial_rotary_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param patch_size_for_vit: 16\n",
      "INFO:MaxText.pyconfig:Config param penalty_incorrect_answer: -1.0\n",
      "INFO:MaxText.pyconfig:Config param penalty_incorrect_format: -0.5\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size: 12\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size_increment: 2.0\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size_start: 4.0\n",
      "INFO:MaxText.pyconfig:Config param pipeline_delay_activation_forwarding: False\n",
      "INFO:MaxText.pyconfig:Config param pipeline_fsdp_ag_once: False\n",
      "INFO:MaxText.pyconfig:Config param pipeline_parallel_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param pixel_shuffle_ratio_for_vit: 0.5\n",
      "INFO:MaxText.pyconfig:Config param posemb_type_for_vit: learn\n",
      "INFO:MaxText.pyconfig:Config param position_id_per_seconds: 25\n",
      "INFO:MaxText.pyconfig:Config param prefill_cache_axis_order: 1,2,0,3\n",
      "INFO:MaxText.pyconfig:Config param prefill_cache_dir: \n",
      "INFO:MaxText.pyconfig:Config param prefill_chunk_size: 256\n",
      "INFO:MaxText.pyconfig:Config param prefill_slice: v5e-16\n",
      "INFO:MaxText.pyconfig:Config param prefix_caching_dram_byte: 100000000000\n",
      "INFO:MaxText.pyconfig:Config param prefix_caching_hbm_byte: 10000000000\n",
      "INFO:MaxText.pyconfig:Config param profile_cleanly: True\n",
      "INFO:MaxText.pyconfig:Config param profile_periodically_period: -1\n",
      "INFO:MaxText.pyconfig:Config param profiler: ProfilerType.NONE\n",
      "INFO:MaxText.pyconfig:Config param profiler_steps: 5\n",
      "INFO:MaxText.pyconfig:Config param projector_dropout_for_vit: 0.0\n",
      "INFO:MaxText.pyconfig:Config param projector_input_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param projector_output_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param prometheus_port: 0\n",
      "INFO:MaxText.pyconfig:Config param prompt: I love to\n",
      "INFO:MaxText.pyconfig:Config param q_lora_rank: 0\n",
      "INFO:MaxText.pyconfig:Config param qk_nope_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param qk_rope_head_dim: 64\n",
      "INFO:MaxText.pyconfig:Config param qkv_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param quant_cfg_path: \n",
      "INFO:MaxText.pyconfig:Config param quantization: QuantizationType.NONE\n",
      "INFO:MaxText.pyconfig:Config param quantization_local_shard_count: 16\n",
      "INFO:MaxText.pyconfig:Config param quantize_kvcache: False\n",
      "INFO:MaxText.pyconfig:Config param query_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param ragged_block_size: 256\n",
      "INFO:MaxText.pyconfig:Config param rampup_end_step: 0\n",
      "INFO:MaxText.pyconfig:Config param rampup_samples_per_increment_to_load: None\n",
      "INFO:MaxText.pyconfig:Config param reasoning_end_token: </reasoning>\n",
      "INFO:MaxText.pyconfig:Config param reasoning_start_token: <reasoning>\n",
      "INFO:MaxText.pyconfig:Config param record_internal_nn_metrics: 0\n",
      "INFO:MaxText.pyconfig:Config param remat_policy: full\n",
      "INFO:MaxText.pyconfig:Config param remat_policy_for_vit: minimal\n",
      "INFO:MaxText.pyconfig:Config param replicate_quant_scale: False\n",
      "INFO:MaxText.pyconfig:Config param replicator_backup_interval_minutes: 0\n",
      "INFO:MaxText.pyconfig:Config param report_heartbeat_metric_for_gcp_monitoring: False\n",
      "INFO:MaxText.pyconfig:Config param report_performance_metric_for_gcp_monitoring: False\n",
      "INFO:MaxText.pyconfig:Config param reshape_q: False\n",
      "INFO:MaxText.pyconfig:Config param return_log_prob: False\n",
      "INFO:MaxText.pyconfig:Config param reuse_example_batch: 0\n",
      "INFO:MaxText.pyconfig:Config param reward_exact_format_match: 3.0\n",
      "INFO:MaxText.pyconfig:Config param reward_partial_format_match: 0.5\n",
      "INFO:MaxText.pyconfig:Config param reward_ratio_guess_to_answer_high: 0.5\n",
      "INFO:MaxText.pyconfig:Config param reward_ratio_guess_to_answer_low: 0.25\n",
      "INFO:MaxText.pyconfig:Config param reward_white_space_format_match: 1.5\n",
      "INFO:MaxText.pyconfig:Config param rl: {'num_generations': 2, 'num_iterations': 1, 'grpo_beta': 0.08, 'grpo_epsilon': 0.2, 'loss_algo': 'grpo'}\n",
      "INFO:MaxText.pyconfig:Config param rollout_data_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param rollout_tensor_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param rope_attention_scaling: False\n",
      "INFO:MaxText.pyconfig:Config param rope_factor: 40\n",
      "INFO:MaxText.pyconfig:Config param rope_interleave: True\n",
      "INFO:MaxText.pyconfig:Config param rope_linear_scaling_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param rope_max_timescale: 1000000\n",
      "INFO:MaxText.pyconfig:Config param rope_min_timescale: 1\n",
      "INFO:MaxText.pyconfig:Config param rope_theta_for_vit: 10000\n",
      "INFO:MaxText.pyconfig:Config param rope_truncate: True\n",
      "INFO:MaxText.pyconfig:Config param rope_type: RopeType.DEFAULT\n",
      "INFO:MaxText.pyconfig:Config param rope_use_scale: True\n",
      "INFO:MaxText.pyconfig:Config param routed_bias: False\n",
      "INFO:MaxText.pyconfig:Config param routed_bias_update_rate: 0.0\n",
      "INFO:MaxText.pyconfig:Config param routed_scaling_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param routed_score_func: \n",
      "INFO:MaxText.pyconfig:Config param run_name: qwen3-omni-30b-a3b_2026-02-06-16-00\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_compute: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dkv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dkv_compute: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dq: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q_dkv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q_dq: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_k_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sa_q_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sa_use_fused_bwd_kernel: False\n",
      "INFO:MaxText.pyconfig:Config param sa_v_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sampler_devices_fraction: 0.5\n",
      "INFO:MaxText.pyconfig:Config param save_checkpoint_on_completion: True\n",
      "INFO:MaxText.pyconfig:Config param save_config_to_gcs: False\n",
      "INFO:MaxText.pyconfig:Config param save_quantized_params_path: \n",
      "INFO:MaxText.pyconfig:Config param scale_embedding_for_audio: True\n",
      "INFO:MaxText.pyconfig:Config param scan_layers: False\n",
      "INFO:MaxText.pyconfig:Config param scan_layers_per_stage: False\n",
      "INFO:MaxText.pyconfig:Config param scan_pipeline_iterations: True\n",
      "INFO:MaxText.pyconfig:Config param set_remat_policy_on_layers_per_stage: False\n",
      "INFO:MaxText.pyconfig:Config param set_remat_policy_on_pipeline_iterations: True\n",
      "INFO:MaxText.pyconfig:Config param sft_train_on_completion_only: False\n",
      "INFO:MaxText.pyconfig:Config param shard_exp_on_fsdp: False\n",
      "INFO:MaxText.pyconfig:Config param shard_mode: ShardMode.AUTO\n",
      "INFO:MaxText.pyconfig:Config param shard_optimizer_over_data: False\n",
      "INFO:MaxText.pyconfig:Config param sharding_strategy: None\n",
      "INFO:MaxText.pyconfig:Config param sharding_tolerance: 0.02\n",
      "INFO:MaxText.pyconfig:Config param shardy: True\n",
      "INFO:MaxText.pyconfig:Config param shared_experts: 1\n",
      "INFO:MaxText.pyconfig:Config param sinkhorn_iterations: 20\n",
      "INFO:MaxText.pyconfig:Config param skip_first_n_steps_for_profiler: 1\n",
      "INFO:MaxText.pyconfig:Config param skip_jax_distributed_system: True\n",
      "INFO:MaxText.pyconfig:Config param sliding_window_size: 0\n",
      "INFO:MaxText.pyconfig:Config param solution_end_token: </answer>\n",
      "INFO:MaxText.pyconfig:Config param solution_start_token: <answer>\n",
      "INFO:MaxText.pyconfig:Config param source_checkpoint_layout: orbax\n",
      "INFO:MaxText.pyconfig:Config param sparse_matmul: True\n",
      "INFO:MaxText.pyconfig:Config param spatial_merge_size_for_vit: 2\n",
      "INFO:MaxText.pyconfig:Config param stack_prefill_result_cache: False\n",
      "INFO:MaxText.pyconfig:Config param stack_trace_interval_seconds: 600\n",
      "INFO:MaxText.pyconfig:Config param stack_trace_to_cloud: False\n",
      "INFO:MaxText.pyconfig:Config param step_deviation_interval_seconds: 30\n",
      "INFO:MaxText.pyconfig:Config param steps: 150001\n",
      "INFO:MaxText.pyconfig:Config param student_overrides: {}\n",
      "INFO:MaxText.pyconfig:Config param subslice_shape: \n",
      "INFO:MaxText.pyconfig:Config param swap_space_vllm_gb: 2\n",
      "INFO:MaxText.pyconfig:Config param target_eval_loss: 0.0\n",
      "INFO:MaxText.pyconfig:Config param teacher_overrides: {}\n",
      "INFO:MaxText.pyconfig:Config param temperature_tuning: False\n",
      "INFO:MaxText.pyconfig:Config param temporal_patch_size_for_vit: 2\n",
      "INFO:MaxText.pyconfig:Config param tensorboard_dir: gs://arabic-asr-dataset/checkpoints/qwen3-omni-30b-a3b-thinking/qwen3-omni-30b-a3b_2026-02-06-16-00/tensorboard/\n",
      "INFO:MaxText.pyconfig:Config param tensors_on_device: None\n",
      "INFO:MaxText.pyconfig:Config param tensors_to_offload: None\n",
      "INFO:MaxText.pyconfig:Config param tile_size_for_vit: 336\n",
      "INFO:MaxText.pyconfig:Config param tokenize_eval_data: True\n",
      "INFO:MaxText.pyconfig:Config param tokenize_train_data: True\n",
      "INFO:MaxText.pyconfig:Config param tokenizer_path: /home/abdo1819/maxtext/src/maxtext/assets/tokenizers/tokenizer.llama2\n",
      "INFO:MaxText.pyconfig:Config param tokenizer_type: TokenizerType.SENTENCEPIECE\n",
      "INFO:MaxText.pyconfig:Config param topk_routing_group: -1\n",
      "INFO:MaxText.pyconfig:Config param train_data_columns: ['text']\n",
      "INFO:MaxText.pyconfig:Config param train_fraction: 1.0\n",
      "INFO:MaxText.pyconfig:Config param train_image_column: image\n",
      "INFO:MaxText.pyconfig:Config param train_split: train\n",
      "INFO:MaxText.pyconfig:Config param trainable_position_size: -1\n",
      "INFO:MaxText.pyconfig:Config param trainer_devices_fraction: 0.5\n",
      "INFO:MaxText.pyconfig:Config param upload_all_profiler_results: False\n",
      "INFO:MaxText.pyconfig:Config param use_2d_fsdp_sharding: False\n",
      "INFO:MaxText.pyconfig:Config param use_audio: True\n",
      "INFO:MaxText.pyconfig:Config param use_audio_in_video: False\n",
      "INFO:MaxText.pyconfig:Config param use_batch_split_schedule: False\n",
      "INFO:MaxText.pyconfig:Config param use_chat_template: False\n",
      "INFO:MaxText.pyconfig:Config param use_chunked_prefill: False\n",
      "INFO:MaxText.pyconfig:Config param use_custom_sort_vjp: True\n",
      "INFO:MaxText.pyconfig:Config param use_dpo: False\n",
      "INFO:MaxText.pyconfig:Config param use_grpo: True\n",
      "INFO:MaxText.pyconfig:Config param use_iota_embed: False\n",
      "INFO:MaxText.pyconfig:Config param use_jax_splash: False\n",
      "INFO:MaxText.pyconfig:Config param use_max_logit_estimate: -1\n",
      "INFO:MaxText.pyconfig:Config param use_mrope: True\n",
      "INFO:MaxText.pyconfig:Config param use_multimodal: True\n",
      "INFO:MaxText.pyconfig:Config param use_pathways: True\n",
      "INFO:MaxText.pyconfig:Config param use_post_attn_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_post_ffw_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_qk_norm: True\n",
      "INFO:MaxText.pyconfig:Config param use_qk_norm_in_gdn: True\n",
      "INFO:MaxText.pyconfig:Config param use_qwix_quantization: False\n",
      "INFO:MaxText.pyconfig:Config param use_ragged_attention: False\n",
      "INFO:MaxText.pyconfig:Config param use_random_routing: False\n",
      "INFO:MaxText.pyconfig:Config param use_replicator_service: False\n",
      "INFO:MaxText.pyconfig:Config param use_ring_of_experts: False\n",
      "INFO:MaxText.pyconfig:Config param use_sft: False\n",
      "INFO:MaxText.pyconfig:Config param use_sparse_indexer: False\n",
      "INFO:MaxText.pyconfig:Config param use_splash_scheduler: False\n",
      "INFO:MaxText.pyconfig:Config param use_tokamax_gmm: False\n",
      "INFO:MaxText.pyconfig:Config param use_tokamax_splash: False\n",
      "INFO:MaxText.pyconfig:Config param use_truncation: True\n",
      "INFO:MaxText.pyconfig:Config param use_tunix_gradient_accumulation: False\n",
      "INFO:MaxText.pyconfig:Config param use_untrainable_positional_embedding: False\n",
      "INFO:MaxText.pyconfig:Config param use_vertex_tensorboard: False\n",
      "INFO:MaxText.pyconfig:Config param using_pipeline_parallelism: False\n",
      "INFO:MaxText.pyconfig:Config param v_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param value_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param vertex_tensorboard_project: \n",
      "INFO:MaxText.pyconfig:Config param vertex_tensorboard_region: \n",
      "INFO:MaxText.pyconfig:Config param video_path: \n",
      "INFO:MaxText.pyconfig:Config param vision_output_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param vllm_additional_config: {}\n",
      "INFO:MaxText.pyconfig:Config param vllm_hf_config_path: \n",
      "INFO:MaxText.pyconfig:Config param vocab_size: 152064\n",
      "INFO:MaxText.pyconfig:Config param warmup_steps_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param weight_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param weight_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_buffer_count: 2\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_buffer_count: 2\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_buffer_count: 2\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_buffer_count: 2\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_buffer_count: 2\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_buffer_count: 2\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wsd_decay_steps_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param wsd_decay_style: WsdDecayStyle.LINEAR\n",
      "INFO:absl:System Information: Jax Version: 0.8.1\n",
      "INFO:absl:System Information: Jaxlib Version: 0.8.1\n",
      "INFO:absl:System Information: Jax Backend: cpu\n",
      "INFO:absl:Lazy loading DISABLED. Loading full HuggingFace model: Qwen/Qwen3-Omni-30B-A3B-Instruct...\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section', 'mrope_interleaved', 'interleaved'}\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section', 'interleaved'}\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section', 'mrope_interleaved', 'interleaved'}\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section', 'interleaved'}\n",
      "Fetching 15 files:   0%|                                 | 0/15 [00:00<?, ?it/s]\n",
      "model-00002-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   0%| | 598k/5.00G [01:09<162:16:41, 8.55kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   0%| | 598k/5.00G [01:24<162:16:41, 8.55kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   0%| | 135k/5.00G [02:11<1357:00:51, 1.02kB/s\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   0%| | 764k/5.00G [02:24<1356:50:36, 1.02kB/s\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   0%| | 631k/5.00G [03:06<410:36:22, 3.38kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   0%| | 631k/5.00G [03:24<410:36:22, 3.38kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   1%|   | 67.7M/5.00G [04:10<3:56:55, 347kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   1%|   | 67.9M/5.00G [04:10<4:15:55, 321kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   7%|   | 336M/5.00G [04:24<4:02:00, 321kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   4%|   | 202M/5.00G [04:24<3:50:28, 347kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   1%|   | 67.7M/5.00G [04:56<5:35:48, 245kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   5%|    | 269M/5.00G [05:03<59:56, 1.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   8%|    | 403M/5.00G [05:03<40:07, 1.91MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:   9%|    | 470M/5.00G [05:14<39:32, 1.91MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   1%|   | 67.7M/5.00G [05:14<5:35:48, 245kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   7%|    | 336M/5.00G [05:14<59:05, 1.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   3%|    | 135M/5.00G [06:01<3:02:56, 443kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:   8%|    | 403M/5.00G [06:01<47:23, 1.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   4%|   | 202M/5.00G [06:14<3:00:24, 443kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  11%|    | 537M/5.00G [06:14<46:00, 1.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  11%|    | 537M/5.00G [07:07<48:58, 1.52MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   5%|   | 269M/5.00G [07:07<1:30:48, 868kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  11%|    | 537M/5.00G [07:24<48:58, 1.52MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:   9%|   | 470M/5.00G [07:24<1:26:56, 868kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  12%|    | 604M/5.00G [07:44<41:31, 1.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  13%|    | 671M/5.00G [08:04<40:53, 1.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  12%|    | 604M/5.00G [08:36<57:33, 1.27MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  12%|    | 604M/5.00G [08:54<57:33, 1.27MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  11%|    | 537M/5.00G [08:58<50:23, 1.48MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  11%|    | 537M/5.00G [09:14<50:23, 1.48MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  12%|   | 605M/5.00G [09:48<1:19:00, 927kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  13%|   | 672M/5.00G [10:04<1:17:48, 927kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  12%|    | 604M/5.00G [10:06<54:06, 1.35MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  13%|    | 671M/5.00G [10:24<53:17, 1.35MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  15%|    | 738M/5.00G [10:56<59:28, 1.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  16%|    | 806M/5.00G [11:14<58:31, 1.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  15%|   | 739M/5.00G [11:54<1:12:21, 981kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  15%|    | 738M/5.00G [12:13<57:37, 1.23MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  17%|    | 873M/5.00G [12:13<52:00, 1.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  21%|  | 1.07G/5.00G [12:14<1:06:39, 981kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  15%|    | 738M/5.00G [12:24<57:37, 1.23MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  17%|    | 873M/5.00G [12:24<52:00, 1.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   0%| | 866k/5.00G [12:40<1218:19:11, 1.14kB/s\u001b[A\n",
      "model-00002-of-00015.safetensors:   1%| | 68.0M/5.00G [12:54<1201:57:44, 1.14kB/\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  22%|   | 1.08G/5.00G [13:08<34:35, 1.89MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  19%|    | 940M/5.00G [13:22<54:35, 1.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   1%| | 67.0M/5.00G [13:22<16:24:37, 83.5kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   3%|    | 135M/5.00G [13:23<5:45:58, 234kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  23%|   | 1.14G/5.00G [13:24<33:59, 1.89MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   1%| | 67.0M/5.00G [13:34<16:24:37, 83.5kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   3%|    | 135M/5.00G [13:34<5:45:58, 234kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  21%|   | 1.07G/5.00G [13:34<52:46, 1.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  16%|  | 805M/5.00G [13:59<1:07:19, 1.04MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00007-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00015.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  17%|  | 873M/5.00G [14:14<1:06:15, 1.04MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  24%|   | 1.21G/5.00G [14:53<37:39, 1.68MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   3%|    | 134M/5.00G [15:01<7:49:36, 173kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  22%|   | 1.07G/5.00G [15:02<51:12, 1.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  24%|   | 1.21G/5.00G [15:04<37:39, 1.68MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   3%|    | 134M/5.00G [15:14<7:49:36, 173kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  23%|   | 1.14G/5.00G [15:14<50:20, 1.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  19%|  | 940M/5.00G [15:59<1:03:39, 1.06MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  20%| | 1.01G/5.00G [16:14<1:02:36, 1.06MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   3%|    | 135M/5.00G [17:08<9:54:14, 136kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   4%|   | 202M/5.00G [17:10<5:11:40, 256kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  24%|   | 1.21G/5.00G [17:10<52:55, 1.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   3%|    | 135M/5.00G [17:24<9:54:14, 136kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   7%|   | 336M/5.00G [17:24<5:02:57, 256kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  24%|   | 1.21G/5.00G [17:24<52:55, 1.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  21%|   | 1.07G/5.00G [17:52<59:13, 1.10MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  21%|   | 1.07G/5.00G [18:04<59:13, 1.10MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   4%|   | 202M/5.00G [18:11<5:08:20, 259kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  26%|   | 1.28G/5.00G [18:21<54:42, 1.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   5%|   | 269M/5.00G [18:24<5:04:01, 259kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  30%|  | 1.48G/5.00G [18:34<51:45, 1.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  26%|  | 1.28G/5.00G [19:10<1:08:20, 908kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  27%|  | 1.34G/5.00G [19:24<1:07:06, 908kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  23%|  | 1.14G/5.00G [20:01<1:11:00, 905kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  23%|  | 1.14G/5.00G [20:14<1:11:00, 905kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:   7%|   | 336M/5.00G [20:22<2:43:24, 475kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:  11%|   | 537M/5.00G [20:34<2:36:21, 475kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   8%|   | 403M/5.00G [21:00<2:43:30, 468kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  28%|  | 1.41G/5.00G [21:03<1:01:02, 980kB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:   9%|   | 470M/5.00G [21:14<2:41:07, 468kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  28%|  | 1.41G/5.00G [21:14<1:01:02, 980kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00015.safetensors:   1%| | 67.0M/5.00G [13:37<16:42:36, 82.0kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00015.safetensors:   3%|  | 134M/5.00G [13:56<16:28:57, 82.0kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  24%|  | 1.21G/5.00G [22:13<1:21:42, 773kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:  12%|   | 604M/5.00G [22:13<1:15:24, 971kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  31%|  | 1.54G/5.00G [22:17<50:45, 1.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:  11%|   | 537M/5.00G [22:17<1:54:53, 647kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  30%|  | 1.48G/5.00G [22:17<1:00:53, 964kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00015.safetensors:   4%|   | 201M/5.00G [14:43<4:41:48, 284kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:  13%|   | 671M/5.00G [22:24<1:14:15, 971kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  24%|  | 1.21G/5.00G [22:24<1:21:42, 773kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00015.safetensors:   7%|   | 335M/5.00G [14:56<4:33:55, 284kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:  11%|   | 537M/5.00G [22:34<1:54:53, 647kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  30%|  | 1.48G/5.00G [22:34<1:00:53, 964kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  31%|  | 1.54G/5.00G [22:34<50:45, 1.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  26%|  | 1.27G/5.00G [22:46<1:08:29, 906kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  27%|  | 1.34G/5.00G [23:04<1:07:15, 906kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  32%|  | 1.61G/5.00G [23:40<52:49, 1.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:  15%|  | 738M/5.00G [23:40<1:04:42, 1.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:  12%|   | 604M/5.00G [23:48<1:50:12, 664kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00008-of-00015.safetensors:  17%|  | 872M/5.00G [23:54<1:02:40, 1.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  32%|  | 1.61G/5.00G [23:54<52:49, 1.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:  15%|   | 739M/5.00G [24:04<1:46:50, 664kB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  28%|  | 1.41G/5.00G [24:15<55:23, 1.08MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  31%|  | 1.54G/5.00G [24:18<1:08:41, 838kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  32%|  | 1.61G/5.00G [24:34<1:07:21, 838kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  28%|  | 1.41G/5.00G [24:34<55:23, 1.08MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  34%|   | 1.68G/5.00G [25:08<55:41, 994kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  34%|  | 1.68G/5.00G [25:21<51:16, 1.08MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:  16%|   | 806M/5.00G [25:21<1:10:21, 993kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  34%|   | 1.68G/5.00G [25:24<55:41, 994kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00015.safetensors:  16%|   | 806M/5.00G [25:34<1:10:21, 993kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00015.safetensors:  35%|  | 1.75G/5.00G [25:34<50:14, 1.08MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  30%|  | 1.48G/5.00G [26:28<1:08:15, 860kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00006-of-00015.safetensors:  30%|  | 1.48G/5.00G [26:44<1:08:14, 860kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  35%|  | 1.75G/5.00G [37:05<2:43:22, 332kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00005-of-00015.safetensors:  36%|  | 1.81G/5.00G [37:24<2:40:00, 332kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A^C\n",
      "Cancellation requested; stopping current tasks.\n"
     ]
    }
   ],
   "source": [
    "!python src/MaxText/utils/ckpt_conversion/to_maxtext.py \\\n",
    "      src/MaxText/configs/models/qwen3-omni-30b-a3b.yml \\\n",
    "      model_name=\"qwen3-omni-30b-a3b\" \\\n",
    "      base_output_directory=$MODEL_CHECKPOINT_PATH \\\n",
    "      hf_access_token=$HF_TOKEN \\\n",
    "      skip_jax_distributed_system=True \\\n",
    "      scan_layers=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
